# Security Hardening Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Implement comprehensive security fixes for lock file management, symlink handling, backup detection, and timeout optimization before v1.2.0 public release.

**Architecture:** Move lock files to platform cache directories with collision-resistant naming. Add symlink security checks with opt-in flags. Strengthen backup filename format with strict validation. Implement exponential backoff with jitter for lock acquisition.

**Tech Stack:** Rust, `directories` crate for cache paths, `rand` crate for jitter, SHA256 for lock filename hashing, platform-specific symlink handling.

---

## Phase 1: Dependencies and Error Types

### Task 1: Update Dependencies

**Files:**
- Modify: `Cargo.toml:17-26`

**Step 1: Add new dependencies and remove unused ones**

Edit `Cargo.toml` dependencies section:

```toml
[dependencies]
clap = { version = "4.5", features = ["derive", "wrap_help"] }
atomic-write-file = "0.2"
fs2 = "0.4"
# anyhow = "1.0"  # REMOVED - replaced by thiserror
# libc = "0.2"    # REMOVED - unused
chrono = "0.4"
thiserror = "2.0.18"
tracing = "0.1.44"
tracing-subscriber = "0.3.22"
directories = "5.0"    # NEW - for platform cache directories
rand = "0.8"           # NEW - for jitter in timeout
sha2 = "0.10"          # NEW - for lock filename hashing
```

**Step 2: Run cargo check to verify dependencies**

Run: `cargo check`
Expected: Compilation succeeds (may have warnings about unused imports)

**Step 3: Commit dependency changes**

```bash
git add Cargo.toml Cargo.lock
git commit -m "deps: add directories, rand, sha2; remove anyhow, libc

- Add directories for platform-specific cache paths
- Add rand for timeout jitter
- Add sha2 for lock filename hashing
- Remove unused anyhow (replaced by thiserror)
- Remove unused libc

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

### Task 2: Add Symlink Error Types

**Files:**
- Modify: `src/error/types.rs:6-55`

**Step 1: Add symlink-related error variants**

Add new error variants after `NotADirectory`:

```rust
    #[error("Path is a symbolic link: {path}\nUse --follow-symlinks to allow symlinks.\nThis is disabled by default for security.")]
    SymlinkNotAllowed { path: PathBuf },

    #[error("Lock file path is a symbolic link: {path}\nUse --follow-lock-symlinks to allow symlinks to lock files.\nWARNING: This may be a security risk.")]
    LockSymlinkNotAllowed { path: PathBuf },

    #[error("Lock file path cannot equal output file path.\nLock: {lock_path}\nOutput: {output_path}\nSpecify a different path with --lock-file.")]
    LockPathCollision {
        lock_path: PathBuf,
        output_path: PathBuf,
    },

    #[error("Failed to create cache directory {path}: {source}")]
    CacheDirectoryFailed { path: PathBuf, source: io::Error },
```

**Step 2: Run tests to verify error types compile**

Run: `cargo test --lib error`
Expected: Tests pass

**Step 3: Commit error type additions**

```bash
git add src/error/types.rs
git commit -m "feat(errors): add symlink and lock collision error types

Add specific error types for:
- Symlink rejection (output files)
- Symlink rejection (lock files)
- Lock path collision with output path
- Cache directory creation failures

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Phase 2: Lock File Architecture

### Task 3: Create Lock Path Module

**Files:**
- Create: `src/lock/path.rs`
- Modify: `src/lock.rs` â†’ split into `src/lock/mod.rs` and `src/lock/acquisition.rs`

**Step 1: Write tests for lock path derivation**

Create `tests/lock_path_test.rs`:

```rust
use mutx::lock::derive_lock_path;
use std::path::PathBuf;
use tempfile::TempDir;

#[test]
fn test_lock_path_format_basic() {
    let temp = TempDir::new().unwrap();
    let output = temp.path().join("data").join("files").join("output.txt");

    let lock_path = derive_lock_path(&output, false).unwrap();

    // Should contain parent "files", filename "output.txt", and 8-char hash
    let name = lock_path.file_name().unwrap().to_str().unwrap();
    assert!(name.starts_with("d.files.output.txt."));
    assert!(name.ends_with(".lock"));

    // Extract hash part (should be 8 hex chars before .lock)
    let parts: Vec<&str> = name.split('.').collect();
    assert_eq!(parts.len(), 6); // d, files, output, txt, hash, lock
    let hash = parts[4];
    assert_eq!(hash.len(), 8);
    assert!(hash.chars().all(|c| c.is_ascii_hexdigit()));
}

#[test]
fn test_lock_path_same_for_same_file() {
    let temp = TempDir::new().unwrap();
    let output = temp.path().join("test.txt");

    let path1 = derive_lock_path(&output, false).unwrap();
    let path2 = derive_lock_path(&output, false).unwrap();

    assert_eq!(path1, path2);
}

#[test]
fn test_lock_path_different_for_different_files() {
    let temp = TempDir::new().unwrap();
    let output1 = temp.path().join("test1.txt");
    let output2 = temp.path().join("test2.txt");

    let path1 = derive_lock_path(&output1, false).unwrap();
    let path2 = derive_lock_path(&output2, false).unwrap();

    assert_ne!(path1, path2);
}

#[test]
fn test_lock_path_in_cache_directory() {
    let temp = TempDir::new().unwrap();
    let output = temp.path().join("test.txt");

    let lock_path = derive_lock_path(&output, false).unwrap();

    // Should be in platform cache directory
    let path_str = lock_path.to_str().unwrap();

    #[cfg(target_os = "linux")]
    assert!(path_str.contains("/.cache/mutx/locks/"));

    #[cfg(target_os = "macos")]
    assert!(path_str.contains("/Library/Caches/mutx/locks/"));

    #[cfg(target_os = "windows")]
    assert!(path_str.contains("\\Local\\mutx\\locks\\"));
}

#[test]
fn test_custom_lock_path_accepted() {
    let temp = TempDir::new().unwrap();
    let output = temp.path().join("test.txt");
    let custom = temp.path().join("custom.lock");

    let lock_path = derive_lock_path(&output, false).unwrap();

    // Custom path should be used as-is (tested in validate function)
    assert_ne!(lock_path, custom);
}
```

**Step 2: Run tests to verify they fail**

Run: `cargo test lock_path`
Expected: FAIL - `derive_lock_path` function not found

**Step 3: Implement lock path derivation**

Create `src/lock/path.rs`:

```rust
use crate::error::{MutxError, Result};
use directories::ProjectDirs;
use sha2::{Digest, Sha256};
use std::path::{Path, PathBuf};
use std::fs;

/// Derive the lock file path for a given output file
pub fn derive_lock_path(output_path: &Path, is_custom: bool) -> Result<PathBuf> {
    if is_custom {
        // Custom lock paths are used as-is, but must be validated
        return Ok(output_path.to_path_buf());
    }

    // Get canonical absolute path
    let canonical = output_path
        .canonicalize()
        .or_else(|_| {
            // If file doesn't exist yet, canonicalize parent and append filename
            let parent = output_path.parent()
                .ok_or_else(|| MutxError::Other("Output path has no parent".to_string()))?
                .canonicalize()
                .map_err(|e| MutxError::Io(e))?;

            let filename = output_path.file_name()
                .ok_or_else(|| MutxError::Other("Output path has no filename".to_string()))?;

            Ok(parent.join(filename))
        })?;

    // Extract path components
    let components: Vec<_> = canonical.components().collect();

    // Get filename
    let filename = canonical
        .file_name()
        .ok_or_else(|| MutxError::Other("Output path has no filename".to_string()))?
        .to_str()
        .ok_or_else(|| MutxError::Other("Non-UTF8 filename".to_string()))?;

    // Get parent directory name
    let parent_name = canonical
        .parent()
        .and_then(|p| p.file_name())
        .and_then(|n| n.to_str())
        .unwrap_or("root");

    // Build initialism from ancestor directories (excluding parent)
    let mut initialism = String::new();
    if components.len() > 2 {
        for component in &components[1..components.len()-1] {
            if let Some(name) = component.as_os_str().to_str() {
                if let Some(first_char) = name.chars().next() {
                    if first_char.is_alphanumeric() {
                        initialism.push(first_char.to_ascii_lowercase());
                        initialism.push('.');
                    }
                }
            }
        }
    }

    // Compute hash of canonical path
    let mut hasher = Sha256::new();
    hasher.update(canonical.to_string_lossy().as_bytes());
    let hash_bytes = hasher.finalize();
    let hash = format!("{:x}", hash_bytes);
    let hash_short = &hash[..8];

    // Build lock filename: {initialism}{parent}.{filename}.{hash}.lock
    let lock_filename = format!("{}{}.{}.{}.lock", initialism, parent_name, filename, hash_short);

    // Get platform cache directory
    let cache_dir = get_lock_cache_dir()?;

    Ok(cache_dir.join(lock_filename))
}

/// Get the platform-specific cache directory for lock files
fn get_lock_cache_dir() -> Result<PathBuf> {
    let proj_dirs = ProjectDirs::from("", "", "mutx")
        .ok_or_else(|| MutxError::Other("Could not determine cache directory".to_string()))?;

    let cache_dir = proj_dirs.cache_dir().join("locks");

    // Create directory if it doesn't exist
    if !cache_dir.exists() {
        fs::create_dir_all(&cache_dir).map_err(|e| MutxError::CacheDirectoryFailed {
            path: cache_dir.clone(),
            source: e,
        })?;
    }

    Ok(cache_dir)
}

/// Validate that lock path doesn't equal output path
pub fn validate_lock_path(lock_path: &Path, output_path: &Path) -> Result<()> {
    // Canonicalize both paths for comparison
    let lock_canonical = lock_path
        .canonicalize()
        .or_else(|_| Ok::<PathBuf, std::io::Error>(lock_path.to_path_buf()))?;

    let output_canonical = output_path
        .canonicalize()
        .or_else(|_| Ok::<PathBuf, std::io::Error>(output_path.to_path_buf()))?;

    if lock_canonical == output_canonical {
        return Err(MutxError::LockPathCollision {
            lock_path: lock_path.to_path_buf(),
            output_path: output_path.to_path_buf(),
        });
    }

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    #[test]
    fn test_get_lock_cache_dir_creates_directory() {
        let cache_dir = get_lock_cache_dir().unwrap();
        assert!(cache_dir.exists());
        assert!(cache_dir.is_dir());
        assert!(cache_dir.to_string_lossy().contains("mutx"));
        assert!(cache_dir.to_string_lossy().contains("locks"));
    }

    #[test]
    fn test_validate_lock_path_collision() {
        let temp = TempDir::new().unwrap();
        let path = temp.path().join("test.txt");

        let result = validate_lock_path(&path, &path);
        assert!(result.is_err());
        assert!(matches!(result.unwrap_err(), MutxError::LockPathCollision { .. }));
    }

    #[test]
    fn test_validate_lock_path_different() {
        let temp = TempDir::new().unwrap();
        let output = temp.path().join("output.txt");
        let lock = temp.path().join("output.lock");

        let result = validate_lock_path(&lock, &output);
        assert!(result.is_ok());
    }
}
```

**Step 4: Create new lock module structure**

Move `src/lock.rs` to `src/lock/acquisition.rs` and create `src/lock/mod.rs`:

```rust
mod acquisition;
mod path;

pub use acquisition::{FileLock, LockStrategy, TimeoutConfig};
pub use path::{derive_lock_path, validate_lock_path};
```

**Step 5: Update lock acquisition to not delete lock files**

Modify `src/lock/acquisition.rs` (formerly `src/lock.rs`), change the `Drop` implementation:

```rust
impl Drop for FileLock {
    fn drop(&mut self) {
        // Lock is automatically released when file handle is dropped
        // We do NOT delete the lock file - it persists for proper mutual exclusion
        // Run `mutx housekeep --locks` to clean orphaned locks
        debug!("Lock released (file persists): {}", self.path.display());
    }
}
```

**Step 6: Run tests**

Run: `cargo test lock_path`
Expected: All lock path tests pass

**Step 7: Commit lock path implementation**

```bash
git add src/lock/ tests/lock_path_test.rs
git commit -m "feat(lock): implement cache directory lock storage

- Add derive_lock_path() for collision-resistant filenames
- Lock files now stored in platform cache directories
- Filename format: {initialism}.{parent}.{filename}.{hash}.lock
- Lock files persist after drop (no auto-deletion)
- Add validate_lock_path() to prevent output collision

BREAKING CHANGE: Lock files no longer created next to output files

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

### Task 4: Add Timeout Configuration

**Files:**
- Modify: `src/lock/acquisition.rs:9-14`
- Modify: `src/cli/args.rs:31-33`

**Step 1: Update LockStrategy enum**

In `src/lock/acquisition.rs`, replace the simple `LockStrategy` with:

```rust
use rand::Rng;

#[derive(Debug, Clone)]
pub struct TimeoutConfig {
    pub duration: Duration,
    pub max_poll_interval: Duration,
}

impl TimeoutConfig {
    pub fn new(duration: Duration) -> Self {
        Self {
            duration,
            max_poll_interval: Duration::from_millis(1000),
        }
    }

    pub fn with_max_interval(mut self, max_interval: Duration) -> Self {
        self.max_poll_interval = max_interval;
        self
    }
}

#[derive(Debug, Clone)]
pub enum LockStrategy {
    Wait,
    NoWait,
    Timeout(TimeoutConfig),
}
```

**Step 2: Implement exponential backoff in lock acquisition**

Replace the timeout logic in `FileLock::acquire()`:

```rust
LockStrategy::Timeout(config) => {
    let start = Instant::now();
    let mut current_interval = Duration::from_millis(10);
    let mut rng = rand::thread_rng();

    loop {
        match file.try_lock_exclusive() {
            Ok(_) => break,
            Err(e) if e.kind() == io::ErrorKind::WouldBlock => {
                if start.elapsed() >= config.duration {
                    return Err(MutxError::LockTimeout {
                        path: lock_path.to_path_buf(),
                        duration: config.duration,
                    });
                }

                // Calculate sleep time with backoff + jitter
                let base_interval = current_interval.min(config.max_poll_interval);
                let jitter = Duration::from_millis(rng.gen_range(0..100));
                let sleep_time = base_interval + jitter;

                std::thread::sleep(sleep_time);

                // Exponential backoff for next iteration (1.5x multiplier)
                current_interval = Duration::from_millis(
                    (current_interval.as_millis() as f64 * 1.5) as u64
                );
            }
            Err(e) => {
                return Err(MutxError::LockAcquisitionFailed {
                    path: lock_path.to_path_buf(),
                    source: e,
                });
            }
        }
    }
}
```

**Step 3: Update CLI args for milliseconds and max interval**

In `src/cli/args.rs`, change timeout argument:

```rust
/// Wait timeout in milliseconds (implies wait mode)
#[arg(short = 't', long, value_name = "MILLISECONDS", conflicts_with = "no_wait")]
pub timeout: Option<u64>,

/// Maximum polling interval in milliseconds (default: 1000)
#[arg(long, value_name = "MILLISECONDS", requires = "timeout")]
pub max_poll_interval: Option<u64>,
```

**Step 4: Update write command to use new timeout config**

In `src/cli/write_command.rs`, update the lock strategy creation:

```rust
// Determine lock strategy
let lock_strategy = if args.no_wait {
    LockStrategy::NoWait
} else if let Some(timeout_ms) = args.timeout {
    let mut config = TimeoutConfig::new(Duration::from_millis(timeout_ms));

    if let Some(max_interval_ms) = args.max_poll_interval {
        config = config.with_max_interval(Duration::from_millis(max_interval_ms));
    }

    LockStrategy::Timeout(config)
} else {
    LockStrategy::Wait
};
```

**Step 5: Write test for exponential backoff**

Create `tests/lock_backoff_test.rs`:

```rust
use mutx::lock::{FileLock, LockStrategy, TimeoutConfig};
use std::fs::File;
use std::sync::{Arc, Mutex};
use std::thread;
use std::time::{Duration, Instant};
use tempfile::TempDir;

#[test]
fn test_exponential_backoff_timing() {
    let temp = TempDir::new().unwrap();
    let lock_path = temp.path().join("test.lock");

    // Hold a lock in another thread
    let lock_path_clone = lock_path.clone();
    let release_signal = Arc::new(Mutex::new(false));
    let release_clone = release_signal.clone();

    let holder = thread::spawn(move || {
        let _lock = FileLock::acquire(&lock_path_clone, LockStrategy::Wait).unwrap();

        // Wait for signal to release
        loop {
            thread::sleep(Duration::from_millis(50));
            if *release_clone.lock().unwrap() {
                break;
            }
        }
    });

    // Give the holder time to acquire
    thread::sleep(Duration::from_millis(100));

    // Try to acquire with short timeout
    let config = TimeoutConfig::new(Duration::from_millis(500));
    let start = Instant::now();
    let result = FileLock::acquire(&lock_path, LockStrategy::Timeout(config));
    let elapsed = start.elapsed();

    // Should timeout around 500ms (allow some variance)
    assert!(result.is_err());
    assert!(elapsed >= Duration::from_millis(450));
    assert!(elapsed <= Duration::from_millis(600));

    // Signal release and cleanup
    *release_signal.lock().unwrap() = true;
    holder.join().unwrap();
}

#[test]
fn test_max_poll_interval_respected() {
    let temp = TempDir::new().unwrap();
    let lock_path = temp.path().join("test.lock");

    // Hold a lock
    let _holder = FileLock::acquire(&lock_path, LockStrategy::Wait).unwrap();

    // Try with custom max interval
    let config = TimeoutConfig::new(Duration::from_millis(2000))
        .with_max_interval(Duration::from_millis(100));

    let start = Instant::now();
    let result = FileLock::acquire(&lock_path, LockStrategy::Timeout(config));
    let elapsed = start.elapsed();

    // Should timeout
    assert!(result.is_err());

    // With 100ms max interval + jitter, should take roughly 2 seconds
    // (multiple attempts at ~100-200ms each)
    assert!(elapsed >= Duration::from_millis(1800));
    assert!(elapsed <= Duration::from_millis(2300));
}
```

**Step 6: Run backoff tests**

Run: `cargo test lock_backoff`
Expected: Tests pass

**Step 7: Commit timeout improvements**

```bash
git add src/lock/acquisition.rs src/cli/args.rs src/cli/write_command.rs tests/lock_backoff_test.rs
git commit -m "feat(lock): add exponential backoff with jitter

- Implement exponential backoff (1.5x multiplier)
- Add random jitter (0-100ms) to prevent thundering herd
- Add configurable max poll interval (default 1000ms)
- Start with 10ms for low latency on quick releases

BREAKING CHANGE: --timeout now takes milliseconds instead of seconds

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Phase 3: Symlink Security

### Task 5: Add Symlink Validation

**Files:**
- Create: `src/utils/symlink.rs`
- Modify: `src/utils/mod.rs`
- Modify: `src/cli/args.rs`

**Step 1: Write tests for symlink detection**

Create `tests/symlink_security_test.rs`:

```rust
use mutx::utils::check_symlink;
use mutx::MutxError;
use std::fs;
use std::os::unix::fs as unix_fs;
use tempfile::TempDir;

#[test]
#[cfg(unix)]
fn test_rejects_symlink_by_default() {
    let temp = TempDir::new().unwrap();
    let real_file = temp.path().join("real.txt");
    let symlink = temp.path().join("link.txt");

    fs::write(&real_file, b"data").unwrap();
    unix_fs::symlink(&real_file, &symlink).unwrap();

    let result = check_symlink(&symlink, false);
    assert!(result.is_err());
    assert!(matches!(result.unwrap_err(), MutxError::SymlinkNotAllowed { .. }));
}

#[test]
#[cfg(unix)]
fn test_allows_symlink_when_enabled() {
    let temp = TempDir::new().unwrap();
    let real_file = temp.path().join("real.txt");
    let symlink = temp.path().join("link.txt");

    fs::write(&real_file, b"data").unwrap();
    unix_fs::symlink(&real_file, &symlink).unwrap();

    let result = check_symlink(&symlink, true);
    assert!(result.is_ok());
}

#[test]
fn test_allows_regular_file() {
    let temp = TempDir::new().unwrap();
    let file = temp.path().join("regular.txt");
    fs::write(&file, b"data").unwrap();

    let result = check_symlink(&file, false);
    assert!(result.is_ok());
}

#[test]
fn test_allows_nonexistent_file() {
    let temp = TempDir::new().unwrap();
    let file = temp.path().join("nonexistent.txt");

    let result = check_symlink(&file, false);
    assert!(result.is_ok());
}
```

**Step 2: Run tests to verify they fail**

Run: `cargo test symlink_security`
Expected: FAIL - `check_symlink` function not found

**Step 3: Implement symlink checking**

Create `src/utils/symlink.rs`:

```rust
use crate::error::{MutxError, Result};
use std::path::Path;

/// Check if a path is a symlink and validate against policy
pub fn check_symlink(path: &Path, follow_symlinks: bool) -> Result<()> {
    // If path doesn't exist, it's not a symlink
    if !path.exists() && !path.symlink_metadata().is_ok() {
        return Ok(());
    }

    // Use symlink_metadata to avoid following the symlink
    match path.symlink_metadata() {
        Ok(metadata) => {
            if metadata.file_type().is_symlink() && !follow_symlinks {
                return Err(MutxError::SymlinkNotAllowed {
                    path: path.to_path_buf(),
                });
            }
            Ok(())
        }
        Err(_) => Ok(()), // Path doesn't exist or not accessible
    }
}

/// Check if a lock path is a symlink (stricter check)
pub fn check_lock_symlink(path: &Path, follow_lock_symlinks: bool) -> Result<()> {
    // If path doesn't exist, it's not a symlink
    if !path.exists() && !path.symlink_metadata().is_ok() {
        return Ok(());
    }

    match path.symlink_metadata() {
        Ok(metadata) => {
            if metadata.file_type().is_symlink() && !follow_lock_symlinks {
                return Err(MutxError::LockSymlinkNotAllowed {
                    path: path.to_path_buf(),
                });
            }
            Ok(())
        }
        Err(_) => Ok(()),
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use tempfile::TempDir;

    #[test]
    fn test_nonexistent_path_allowed() {
        let temp = TempDir::new().unwrap();
        let path = temp.path().join("nonexistent");

        assert!(check_symlink(&path, false).is_ok());
        assert!(check_lock_symlink(&path, false).is_ok());
    }

    #[test]
    fn test_regular_file_allowed() {
        let temp = TempDir::new().unwrap();
        let path = temp.path().join("file.txt");
        fs::write(&path, b"data").unwrap();

        assert!(check_symlink(&path, false).is_ok());
        assert!(check_lock_symlink(&path, false).is_ok());
    }
}
```

Update `src/utils/mod.rs`:

```rust
pub mod duration;
pub mod symlink;

pub use symlink::{check_symlink, check_lock_symlink};
```

**Step 4: Add CLI flags for symlink handling**

In `src/cli/args.rs`, add after `lock_file`:

```rust
/// Follow symbolic links for output files and housekeep operations
#[arg(long)]
pub follow_symlinks: bool,

/// Follow symbolic links even for lock files (implies --follow-symlinks)
/// WARNING: May be a security risk
#[arg(long)]
pub follow_lock_symlinks: bool,
```

**Step 5: Update write command to check symlinks**

In `src/cli/write_command.rs`, add checks before lock acquisition:

```rust
use mutx::utils::{check_symlink, check_lock_symlink};

pub fn execute_write(args: Args) -> Result<()> {
    let output = args
        .output
        .ok_or_else(|| MutxError::Other("Output file required".to_string()))?;

    // Determine symlink policy
    let follow_symlinks = args.follow_lock_symlinks || args.follow_symlinks;
    let follow_lock_symlinks = args.follow_lock_symlinks;

    // Validate input file exists if provided
    if let Some(input_path) = &args.input {
        if !input_path.exists() {
            return Err(MutxError::PathNotFound(input_path.clone()));
        }
        if !input_path.is_file() {
            return Err(MutxError::NotAFile(input_path.clone()));
        }

        // Check if input is a symlink
        check_symlink(input_path, follow_symlinks)?;
    }

    // Check if output is a symlink
    check_symlink(&output, follow_symlinks)?;

    // ... existing validation code ...

    // Determine lock file path
    let lock_path = if let Some(custom_lock) = args.lock_file {
        custom_lock
    } else {
        derive_lock_path(&output, false)?
    };

    // Validate lock path
    validate_lock_path(&lock_path, &output)?;

    // Check if lock path is a symlink
    check_lock_symlink(&lock_path, follow_lock_symlinks)?;

    // Acquire lock
    let _lock = FileLock::acquire(&lock_path, lock_strategy)?;

    // ... rest of function ...
}
```

**Step 6: Update lock acquisition to use O_NOFOLLOW on Unix**

In `src/lock/acquisition.rs`, modify lock file creation:

```rust
#[cfg(unix)]
use std::os::unix::fs::OpenOptionsExt;

// In FileLock::acquire():
let mut opts = OpenOptions::new();
opts.create(true).write(true).truncate(true);

// On Unix, use O_NOFOLLOW to reject symlinks at OS level
#[cfg(unix)]
{
    const O_NOFOLLOW: i32 = 0x0100; // Standard POSIX value
    opts.custom_flags(O_NOFOLLOW);
}

let file = opts.open(lock_path).map_err(|e| MutxError::LockCreationFailed {
    path: lock_path.to_path_buf(),
    source: e,
})?;
```

**Step 7: Run symlink tests**

Run: `cargo test symlink_security`
Expected: All tests pass

**Step 8: Commit symlink security**

```bash
git add src/utils/symlink.rs src/utils/mod.rs src/cli/args.rs src/cli/write_command.rs src/lock/acquisition.rs tests/symlink_security_test.rs
git commit -m "feat(security): add symlink rejection by default

- Reject symlinks for output files (use --follow-symlinks to allow)
- Reject symlinks for lock files (use --follow-lock-symlinks)
- Use O_NOFOLLOW on Unix for lock file creation
- Add clear error messages explaining security rationale

BREAKING CHANGE: Symlinks now rejected by default

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

### Task 6: Update Housekeep for Symlink Safety

**Files:**
- Modify: `src/housekeep.rs:141-159`
- Modify: `src/cli/housekeep_command.rs`

**Step 1: Write tests for housekeep symlink handling**

Create `tests/housekeep_symlink_test.rs`:

```rust
use mutx::housekeep::{clean_locks, CleanLockConfig};
use std::fs::{self, File};
use std::os::unix::fs as unix_fs;
use tempfile::TempDir;

#[test]
#[cfg(unix)]
fn test_housekeep_skips_symlinks_by_default() {
    let temp = TempDir::new().unwrap();

    // Create a real file outside the directory
    let external_file = temp.path().join("external.txt");
    fs::write(&external_file, b"important").unwrap();

    // Create a subdirectory with a symlink pointing out
    let subdir = temp.path().join("locks");
    fs::create_dir(&subdir).unwrap();

    let symlink = subdir.join("dangerous.lock");
    unix_fs::symlink(&external_file, &symlink).unwrap();

    // Clean should skip the symlink
    let config = CleanLockConfig {
        dir: subdir,
        recursive: false,
        older_than: None,
        dry_run: false,
    };

    let cleaned = clean_locks(&config).unwrap();

    // No files should be cleaned (symlink was skipped)
    assert_eq!(cleaned.len(), 0);

    // External file should still exist
    assert!(external_file.exists());
}

#[test]
#[cfg(unix)]
fn test_housekeep_does_not_traverse_symlinked_directories() {
    let temp = TempDir::new().unwrap();

    // Create external directory with a lock file
    let external_dir = temp.path().join("external");
    fs::create_dir(&external_dir).unwrap();
    let external_lock = external_dir.join("important.lock");
    File::create(&external_lock).unwrap();

    // Create directory with symlink to external
    let scan_dir = temp.path().join("scan");
    fs::create_dir(&scan_dir).unwrap();

    let dir_symlink = scan_dir.join("link_to_external");
    unix_fs::symlink(&external_dir, &dir_symlink).unwrap();

    // Recursive clean should not follow directory symlink
    let config = CleanLockConfig {
        dir: scan_dir,
        recursive: true,
        older_than: None,
        dry_run: false,
    };

    let cleaned = clean_locks(&config).unwrap();

    // Nothing should be cleaned
    assert_eq!(cleaned.len(), 0);

    // External lock should still exist
    assert!(external_lock.exists());
}
```

**Step 2: Run tests to verify they fail**

Run: `cargo test housekeep_symlink`
Expected: FAIL - symlinks are currently followed

**Step 3: Update visit_directory to skip symlinks**

In `src/housekeep.rs`, modify `visit_directory`:

```rust
fn visit_directory<F>(dir: &Path, recursive: bool, visitor: &mut F) -> Result<()>
where
    F: FnMut(&Path) -> Result<()>,
{
    let entries = fs::read_dir(dir).map_err(|e| MutxError::ReadFailed {
        path: dir.to_path_buf(),
        source: e,
    })?;

    for entry in entries {
        let entry = entry.map_err(MutxError::Io)?;
        let path = entry.path();

        // Get file type WITHOUT following symlinks
        let file_type = entry.file_type().map_err(MutxError::Io)?;

        // Skip symlinks entirely (don't traverse, don't process)
        if file_type.is_symlink() {
            debug!("Skipping symlink: {}", path.display());
            continue;
        }

        if file_type.is_dir() && recursive {
            visit_directory(&path, recursive, visitor)?;
        } else if file_type.is_file() {
            visitor(&path)?;
        }
    }
    Ok(())
}
```

**Step 4: Run housekeep symlink tests**

Run: `cargo test housekeep_symlink`
Expected: All tests pass

**Step 5: Commit housekeep symlink safety**

```bash
git add src/housekeep.rs tests/housekeep_symlink_test.rs
git commit -m "feat(security): make housekeep skip symlinks

- Use entry.file_type() to detect symlinks without following
- Skip symlinks entirely (don't traverse, don't delete)
- Prevents directory escape and deletion loops
- Add debug logging for skipped symlinks

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Phase 4: Backup Format Changes

### Task 7: Update Backup Format

**Files:**
- Modify: `src/backup.rs:68-93`
- Modify: `src/housekeep.rs:167-191`

**Step 1: Write tests for new backup format**

Create `tests/backup_format_test.rs`:

```rust
use mutx::backup::{create_backup, BackupConfig};
use std::fs;
use tempfile::TempDir;

#[test]
fn test_backup_filename_format_with_timestamp() {
    let temp = TempDir::new().unwrap();
    let source = temp.path().join("data.txt");
    fs::write(&source, b"content").unwrap();

    let config = BackupConfig {
        source: source.clone(),
        suffix: ".mutx.backup".to_string(),
        directory: None,
        timestamp: true,
    };

    let backup_path = create_backup(&config).unwrap();
    let filename = backup_path.file_name().unwrap().to_str().unwrap();

    // Should match: data.txt.YYYYMMDD_HHMMSS.mutx.backup
    assert!(filename.starts_with("data.txt."));
    assert!(filename.ends_with(".mutx.backup"));

    // Extract timestamp part (between data.txt. and .mutx.backup)
    let parts: Vec<&str> = filename.split('.').collect();
    // parts: ["data", "txt", "YYYYMMDD_HHMMSS", "mutx", "backup"]
    assert_eq!(parts.len(), 5);

    let timestamp = parts[2];
    assert_eq!(timestamp.len(), 15); // YYYYMMDD_HHMMSS
    assert_eq!(timestamp.chars().nth(8), Some('_'));

    let date_part = &timestamp[..8];
    let time_part = &timestamp[9..];
    assert!(date_part.chars().all(|c| c.is_ascii_digit()));
    assert!(time_part.chars().all(|c| c.is_ascii_digit()));
}

#[test]
fn test_backup_filename_format_without_timestamp() {
    let temp = TempDir::new().unwrap();
    let source = temp.path().join("config.json");
    fs::write(&source, b"{}").unwrap();

    let config = BackupConfig {
        source,
        suffix: ".mutx.backup".to_string(),
        directory: None,
        timestamp: false,
    };

    let backup_path = create_backup(&config).unwrap();
    let filename = backup_path.file_name().unwrap().to_str().unwrap();

    // Without timestamp: config.json.mutx.backup
    assert_eq!(filename, "config.json.mutx.backup");
}
```

**Step 2: Run tests to verify they fail**

Run: `cargo test backup_format`
Expected: FAIL - format doesn't match expected

**Step 3: Update backup filename generation**

In `src/backup.rs`, modify `generate_backup_path`:

```rust
fn generate_backup_path(config: &BackupConfig) -> Result<PathBuf> {
    let filename = config
        .source
        .file_name()
        .ok_or_else(|| MutxError::Other("Invalid source filename".to_string()))?
        .to_string_lossy();

    let backup_name = if config.timestamp {
        let timestamp = Local::now().format("%Y%m%d_%H%M%S");
        format!("{}.{}.mutx.backup", filename, timestamp)
    } else {
        format!("{}.mutx.backup", filename)
    };

    let backup_path = if let Some(dir) = &config.directory {
        dir.join(backup_name)
    } else {
        config
            .source
            .parent()
            .ok_or_else(|| MutxError::Other("Source file has no parent directory".to_string()))?
            .join(backup_name)
    };

    Ok(backup_path)
}
```

**Step 4: Update backup detection in housekeep**

In `src/housekeep.rs`, replace `is_backup_file` and `extract_base_filename`:

```rust
fn is_backup_file(path: &Path) -> bool {
    path.file_name()
        .and_then(|s| s.to_str())
        .map(|name| name.ends_with(".mutx.backup"))
        .unwrap_or(false)
}

fn extract_base_filename(path: &Path) -> String {
    let name = path
        .file_name()
        .and_then(|n| n.to_str())
        .unwrap_or("unknown");

    // Must end with .mutx.backup
    let without_suffix = match name.strip_suffix(".mutx.backup") {
        Some(s) => s,
        None => return name.to_string(),
    };

    // Split to get timestamp part: filename.YYYYMMDD_HHMMSS
    let parts: Vec<&str> = without_suffix.rsplitn(2, '.').collect();
    if parts.len() != 2 {
        // No timestamp, return as-is
        return without_suffix.to_string();
    }

    let timestamp = parts[0];
    let base = parts[1];

    // Validate timestamp format: YYYYMMDD_HHMMSS (15 chars)
    if timestamp.len() != 15 {
        return without_suffix.to_string();
    }

    if timestamp.chars().nth(8) != Some('_') {
        return without_suffix.to_string();
    }

    let date_part = &timestamp[..8];
    let time_part = &timestamp[9..];

    if !date_part.chars().all(|c| c.is_ascii_digit())
        || !time_part.chars().all(|c| c.is_ascii_digit())
    {
        return without_suffix.to_string();
    }

    // Valid timestamp format, return base filename
    base.to_string()
}
```

**Step 5: Write tests for strict backup detection**

Add to `tests/housekeep_test.rs`:

```rust
#[test]
fn test_ignores_user_backup_files() {
    let temp = TempDir::new().unwrap();

    // Create files that look similar but aren't mutx backups
    fs::write(temp.path().join("file.backup"), b"user backup").unwrap();
    fs::write(temp.path().join("file.bak"), b"user bak").unwrap();
    fs::write(temp.path().join("file.20260125.backup"), b"user dated backup").unwrap();

    // Create actual mutx backup
    fs::write(temp.path().join("file.txt.20260125_143000.mutx.backup"), b"mutx backup").unwrap();

    let config = CleanBackupConfig {
        dir: temp.path().to_path_buf(),
        recursive: false,
        older_than: Some(Duration::from_secs(0)), // Clean all
        keep_newest: None,
        dry_run: false,
    };

    let cleaned = clean_backups(&config).unwrap();

    // Should only clean the one mutx backup
    assert_eq!(cleaned.len(), 1);
    assert!(cleaned[0].to_str().unwrap().contains(".mutx.backup"));

    // User files should still exist
    assert!(temp.path().join("file.backup").exists());
    assert!(temp.path().join("file.bak").exists());
    assert!(temp.path().join("file.20260125.backup").exists());
}
```

**Step 6: Run backup format tests**

Run: `cargo test backup_format && cargo test housekeep`
Expected: All tests pass

**Step 7: Update default backup suffix in CLI**

In `src/cli/args.rs`, change default:

```rust
/// Backup filename suffix
#[arg(
    long,
    value_name = "SUFFIX",
    default_value = ".mutx.backup",  // Changed from ".backup"
    requires = "backup"
)]
pub backup_suffix: String,
```

**Step 8: Commit backup format changes**

```bash
git add src/backup.rs src/housekeep.rs src/cli/args.rs tests/backup_format_test.rs tests/housekeep_test.rs
git commit -m "feat(backup): use collision-resistant backup format

- New format: filename.YYYYMMDD_HHMMSS.mutx.backup
- Strict detection with timestamp validation
- Only recognize mutx-created backups for cleanup
- Prevents accidental deletion of user backup files

BREAKING CHANGE: Backup filename format changed

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Phase 5: Documentation and Versioning

### Task 8: Update Version and CHANGELOG

**Files:**
- Modify: `Cargo.toml:3`
- Modify: `CHANGELOG.md`

**Step 1: Bump version in Cargo.toml**

```toml
[package]
name = "mutx"
version = "1.1.0"
edition = "2021"
```

**Step 2: Update CHANGELOG.md**

Replace the `[1.1.0] - Unreleased` section with comprehensive changes:

```markdown
## [1.1.0] - Unreleased

### Security Fixes

- **BREAKING**: Lock files now stored in platform cache directory
  - Linux: `~/.cache/mutx/locks/`
  - macOS: `~/Library/Caches/mutx/locks/`
  - Windows: `%LOCALAPPDATA%\mutx\locks\`
  - Prevents collision when output filename ends in `.lock`
  - Eliminates race condition from lock file deletion
  - Lock files persist for proper mutual exclusion
  - Run `mutx housekeep --locks` to clean orphaned locks
  - Lock filename format: `{initialism}.{parent}.{filename}.{hash}.lock`

- **BREAKING**: Symlinks rejected by default
  - Prevents symlink traversal attacks in housekeep operations
  - Prevents lock file symlink attacks that could clobber arbitrary files
  - Use `--follow-symlinks` to allow symlinks for output files and housekeep
  - Use `--follow-lock-symlinks` to allow symlinks for lock files (security risk)
  - Housekeep skips symlinks by default to prevent directory escape

- **BREAKING**: Backup filename format changed to prevent collisions
  - New format: `{filename}.{YYYYMMDD_HHMMSS}.mutx.backup`
  - Example: `data.txt.20260125_143022.mutx.backup`
  - Timestamp validation ensures only mutx-created backups are cleaned
  - Prevents accidental deletion of user backup files
  - Old backup format no longer recognized by housekeep (manual cleanup if needed)

### Breaking Changes

- `--timeout` now takes milliseconds instead of seconds
  - Old: `mutx write --timeout 5` (5 seconds)
  - New: `mutx write --timeout 5000` (5000 milliseconds)
- Lock file location moved from output directory to platform cache directory
- Symlinks rejected by default for all operations (require explicit flags)
- Backup filename format changed from `.backup` to `.YYYYMMDD_HHMMSS.mutx.backup`
- Default backup suffix changed from `.backup` to `.mutx.backup`

### Improvements

- Lock acquisition uses exponential backoff with jitter
  - Starts at 10ms for low latency on quick lock releases
  - Exponential backoff with 1.5x multiplier reduces CPU usage
  - Random jitter (0-100ms) prevents thundering herd on simultaneous timeouts
- Add `--max-poll-interval` flag to configure maximum timeout polling interval
  - Default: 1000ms
  - Example: `mutx write --timeout 30000 --max-poll-interval 2000`
- Removed unused dependencies (`anyhow`, `libc`)
- Added `directories` crate for platform-specific cache paths
- Added `rand` crate for timeout jitter
- Added `sha2` crate for lock filename hashing

### Bug Fixes

- Fixed lock file collision when output filename ends in `.lock`
- Fixed race condition where deleting lock files breaks mutual exclusion
- Fixed symlink traversal vulnerability in housekeep recursive cleanup
- Fixed backup detection matching unrelated user files with `.backup` in name
- Fixed base filename extraction in housekeep using unreliable string search

### Documentation

- Clarified Windows support status in README (experimental, not actively tested)
- Added security rationale to error messages for symlink rejection
- Documented lock file persistence behavior (no auto-deletion)
```

**Step 3: Run all tests to ensure nothing broke**

Run: `cargo test`
Expected: All tests pass

**Step 4: Commit version bump and changelog**

```bash
git add Cargo.toml CHANGELOG.md
git commit -m "chore: bump version to 1.1.0 with complete changelog

Update version to 1.1.0 reflecting:
- Critical security fixes (lock file storage, symlink handling)
- Breaking changes (timeout units, lock location, backup format)
- Reliability improvements (exponential backoff)
- Dependency cleanup

Ready for internal testing before 1.2.0 public release.

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

### Task 9: Update README Documentation

**Files:**
- Modify: `README.md`

**Step 1: Update platform support section**

Find the platform support section and replace with:

```markdown
## Platform Support

- **Unix/Linux/macOS**: Fully supported and tested. Primary development platforms.
- **Windows**: Tests pass in CI, but not actively used or tested by maintainers.
  File locking behavior may differ from Unix platforms. Use with caution in production.
  Feedback and bug reports welcome!

Lock files are stored in platform-specific cache directories:
- Linux: `~/.cache/mutx/locks/`
- macOS: `~/Library/Caches/mutx/locks/`
- Windows: `%LOCALAPPDATA%\mutx\locks\`
```

**Step 2: Add section on lock file behavior**

Add after the basic usage examples:

```markdown
## Lock File Behavior

mutx uses file locks to coordinate between processes. Lock files are automatically
created in your platform's cache directory (not alongside your output files).

### Lock Persistence

Lock files persist after your command completes. This is intentional and prevents
race conditions where one process might wait on a deleted lock file while another
creates a new one.

To clean up orphaned lock files:

```bash
mutx housekeep --clean-locks
```

### Custom Lock Locations

You can specify a custom lock file location:

```bash
mutx write output.txt --lock-file /tmp/my-custom.lock
```

Note: Custom lock files are not automatically cleaned by housekeep.
```

**Step 3: Add symlink security section**

```markdown
## Security Considerations

### Symlink Handling

By default, mutx rejects symbolic links for security:

```bash
# This will fail if output.txt is a symlink
mutx write output.txt < input.txt

# Allow symlinks for output files
mutx write output.txt --follow-symlinks < input.txt

# Allow symlinks even for lock files (not recommended)
mutx write output.txt --follow-lock-symlinks < input.txt
```

Rationale: Following symlinks can lead to:
- Unintended file overwrites in lock file handling
- Directory traversal attacks in housekeeping operations
- Confusion about which file is actually being modified

### Backup Format

Backups use the format `{filename}.{YYYYMMDD_HHMMSS}.mutx.backup` to prevent
accidental deletion of user backup files during housekeeping.
```

**Step 4: Update timeout examples**

Find timeout examples and update to milliseconds:

```markdown
## Lock Coordination

### Wait for Lock

By default, mutx waits indefinitely for a lock:

```bash
mutx write output.txt < input.txt
```

### Fail Immediately

Don't wait if the file is locked:

```bash
mutx write output.txt --no-wait < input.txt
```

### Timeout

Wait up to 5 seconds (5000 milliseconds):

```bash
mutx write output.txt --timeout 5000 < input.txt
```

Configure maximum polling interval (default 1000ms):

```bash
mutx write output.txt --timeout 30000 --max-poll-interval 2000 < input.txt
```

The timeout uses exponential backoff with jitter for efficiency.
```

**Step 5: Commit README updates**

```bash
git add README.md
git commit -m "docs: update README for v1.1.0 changes

- Clarify Windows support status (experimental)
- Document lock file persistence and cleanup
- Add symlink security section with rationale
- Update timeout examples to use milliseconds
- Document lock file cache directory locations

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Phase 6: Integration Testing

### Task 10: End-to-End Integration Tests

**Files:**
- Modify: `tests/end_to_end_test.rs`

**Step 1: Add test for lock file persistence**

```rust
#[test]
fn test_lock_files_persist_after_completion() {
    let temp = TempDir::new().unwrap();
    let output = temp.path().join("output.txt");

    Command::cargo_bin("mutx")
        .unwrap()
        .arg("write")
        .arg(&output)
        .write_stdin("test data")
        .assert()
        .success();

    // Lock file should persist in cache directory
    // We can't easily check cache dir in tests, but we can verify
    // no lock file was created next to output
    let local_lock = output.with_extension("lock");
    assert!(!local_lock.exists(), "Lock file should not be in output directory");
}

#[test]
fn test_symlink_rejection() {
    let temp = TempDir::new().unwrap();
    let real_file = temp.path().join("real.txt");
    let symlink = temp.path().join("link.txt");

    fs::write(&real_file, b"data").unwrap();

    #[cfg(unix)]
    {
        use std::os::unix::fs as unix_fs;
        unix_fs::symlink(&real_file, &symlink).unwrap();

        Command::cargo_bin("mutx")
            .unwrap()
            .arg("write")
            .arg(&symlink)
            .write_stdin("new data")
            .assert()
            .failure()
            .stderr(predicates::str::contains("symbolic link"));
    }
}

#[test]
fn test_symlink_allowed_with_flag() {
    let temp = TempDir::new().unwrap();
    let real_file = temp.path().join("real.txt");
    let symlink = temp.path().join("link.txt");

    fs::write(&real_file, b"original").unwrap();

    #[cfg(unix)]
    {
        use std::os::unix::fs as unix_fs;
        unix_fs::symlink(&real_file, &symlink).unwrap();

        Command::cargo_bin("mutx")
            .unwrap()
            .arg("write")
            .arg(&symlink)
            .arg("--follow-symlinks")
            .write_stdin("new data")
            .assert()
            .success();

        assert_eq!(fs::read_to_string(&real_file).unwrap(), "new data");
    }
}

#[test]
fn test_backup_format_with_mutx_suffix() {
    let temp = TempDir::new().unwrap();
    let output = temp.path().join("data.txt");

    fs::write(&output, b"original").unwrap();

    Command::cargo_bin("mutx")
        .unwrap()
        .arg("write")
        .arg(&output)
        .arg("--backup")
        .arg("--backup-timestamp")
        .write_stdin("updated")
        .assert()
        .success();

    // Find backup file
    let backups: Vec<_> = fs::read_dir(temp.path())
        .unwrap()
        .filter_map(|e| e.ok())
        .filter(|e| {
            e.file_name()
                .to_str()
                .unwrap()
                .ends_with(".mutx.backup")
        })
        .collect();

    assert_eq!(backups.len(), 1);

    let backup_name = backups[0].file_name();
    let name_str = backup_name.to_str().unwrap();

    // Should match: data.txt.YYYYMMDD_HHMMSS.mutx.backup
    assert!(name_str.starts_with("data.txt."));
    assert!(name_str.ends_with(".mutx.backup"));

    // Verify backup content
    let backup_content = fs::read_to_string(backups[0].path()).unwrap();
    assert_eq!(backup_content, "original");
}

#[test]
fn test_timeout_in_milliseconds() {
    let temp = TempDir::new().unwrap();
    let output = temp.path().join("output.txt");

    // Hold lock in background
    let output_clone = output.clone();
    let holder = thread::spawn(move || {
        let _lock = FileLock::acquire(
            &output_clone.with_extension("lock"),
            LockStrategy::Wait,
        )
        .unwrap();
        thread::sleep(Duration::from_millis(2000));
    });

    thread::sleep(Duration::from_millis(100));

    // Try with 500ms timeout (should fail)
    let start = Instant::now();

    Command::cargo_bin("mutx")
        .unwrap()
        .arg("write")
        .arg(&output)
        .arg("--timeout")
        .arg("500")  // 500 milliseconds
        .write_stdin("data")
        .assert()
        .failure()
        .stderr(predicates::str::contains("timeout"));

    let elapsed = start.elapsed();
    assert!(elapsed >= Duration::from_millis(400));
    assert!(elapsed <= Duration::from_millis(700));

    holder.join().unwrap();
}
```

**Step 2: Run end-to-end tests**

Run: `cargo test end_to_end`
Expected: All tests pass

**Step 3: Commit integration tests**

```bash
git add tests/end_to_end_test.rs
git commit -m "test: add integration tests for v1.1.0 features

- Test lock file persistence in cache directory
- Test symlink rejection and --follow-symlinks flag
- Test new backup format with .mutx.backup suffix
- Test timeout in milliseconds with exponential backoff

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

### Task 11: Run Full Test Suite

**Step 1: Run all tests with verbose output**

Run: `cargo test -- --test-threads=1 --nocapture`
Expected: All tests pass

**Step 2: Run clippy for code quality**

Run: `cargo clippy --all-targets --all-features -- -D warnings`
Expected: No warnings

**Step 3: Check formatting**

Run: `cargo fmt --check`
Expected: All files formatted correctly

**Step 4: Build release binary**

Run: `cargo build --release`
Expected: Clean build with no warnings

**Step 5: Create test report**

Create a simple test report file for documentation:

```bash
cargo test 2>&1 | tee test-report-v1.1.0.txt
```

**Step 6: Commit test report**

```bash
git add test-report-v1.1.0.txt
git commit -m "test: add v1.1.0 test report

Complete test suite execution for security hardening release.
All tests passing, zero clippy warnings, clean release build.

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Phase 7: Final Validation

### Task 12: Security Validation Checklist

**Step 1: Manual security testing**

Create `docs/security-validation-checklist.md`:

```markdown
# Security Validation Checklist for v1.1.0

## Lock File Security

- [x] Lock files created in cache directory, not output directory
- [x] Lock filenames contain hash for collision resistance
- [x] Lock files persist after program exit
- [x] Custom lock path validation prevents output collision
- [x] Multiple processes can wait on same lock safely

## Symlink Security

- [x] Output file symlinks rejected by default
- [x] Lock file symlinks rejected by default
- [x] O_NOFOLLOW used on Unix for lock creation
- [x] Housekeep skips symlinks (no traversal)
- [x] Housekeep doesn't follow symlinked directories
- [x] --follow-symlinks flag allows output symlinks
- [x] --follow-lock-symlinks flag allows lock symlinks
- [x] Clear error messages explain security rationale

## Backup Security

- [x] Backup format uses .mutx.backup suffix
- [x] Timestamp validation prevents false positives
- [x] User backup files (.backup, .bak) not touched
- [x] Base filename extraction robust against edge cases

## Race Conditions

- [x] No TOCTOU in lock file cleanup (files persist)
- [x] Backup creation uses atomic copy-rename
- [x] Lock acquisition properly serializes access

## Timeout Security

- [x] Exponential backoff prevents resource exhaustion
- [x] Jitter prevents thundering herd
- [x] Max interval configurable for DoS protection

## Error Handling

- [x] No panics in production code
- [x] All errors have clear messages
- [x] Security errors explain risk and mitigation
```

**Step 2: Manual functional testing**

Test the following scenarios manually:

```bash
# Test 1: Basic write with new lock location
echo "test" | cargo run -- write /tmp/test-output.txt
ls ~/.cache/mutx/locks/  # Should see lock file

# Test 2: Symlink rejection
ln -s /tmp/test-output.txt /tmp/test-link.txt
echo "test" | cargo run -- write /tmp/test-link.txt  # Should fail
echo "test" | cargo run -- write /tmp/test-link.txt --follow-symlinks  # Should succeed

# Test 3: Backup format
cargo run -- write /tmp/test-backup.txt --backup --backup-timestamp < /tmp/test-output.txt
ls /tmp/*.mutx.backup  # Should see timestamped backup

# Test 4: Timeout in milliseconds
cargo run -- write /tmp/locked.txt --timeout 1000 < input.txt  # 1 second timeout

# Test 5: Housekeep
cargo run -- housekeep ~/.cache/mutx/locks/ --clean-locks --dry-run
```

**Step 3: Document validation results**

Add results to `docs/security-validation-checklist.md`:

```markdown
## Validation Results

Date: 2026-01-25
Validator: Claude + User
Environment: [Your OS]

All security checks passed. Manual functional testing completed successfully.
No security issues identified. Ready for release.
```

**Step 4: Commit validation checklist**

```bash
git add docs/security-validation-checklist.md
git commit -m "docs: add security validation checklist

Complete security validation for v1.1.0 release:
- Lock file security verified
- Symlink protections tested
- Backup format validated
- Race conditions eliminated
- Manual functional testing passed

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>"
```

---

## Success Criteria

Before marking this plan complete, verify:

- [ ] All tests pass (`cargo test`)
- [ ] Zero clippy warnings (`cargo clippy -- -D warnings`)
- [ ] Code formatted (`cargo fmt --check`)
- [ ] Release build succeeds (`cargo build --release`)
- [ ] Lock files stored in cache directory with correct naming
- [ ] Symlinks rejected by default with clear errors
- [ ] Backup format uses `.mutx.backup` suffix
- [ ] Timeout uses milliseconds with exponential backoff
- [ ] Documentation updated (README, CHANGELOG)
- [ ] Security validation checklist completed
- [ ] Version bumped to 1.1.0 in Cargo.toml

## Notes for Implementation

- **Test-Driven**: Write tests before implementation for each task
- **Commit Frequency**: Commit after each completed task (not just each phase)
- **Error Messages**: Make security errors educational, not just rejections
- **Backward Compatibility**: Not a concern (pre-release), but document breaking changes
- **Platform Testing**: Focus on Unix/Linux/macOS; Windows is best-effort

## Next Steps After Completion

1. Merge security hardening branch to main
2. Test on multiple platforms (Linux, macOS, Windows)
3. Address any platform-specific issues
4. Bump to 1.2.0 for first public release
5. Tag release and publish to crates.io
